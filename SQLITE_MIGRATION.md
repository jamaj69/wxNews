# SQLite Migration Documentation

**Migration Date:** February 26, 2026  
**Status:** âœ… COMPLETE

## Overview

Successfully migrated the pyTweeter news collection system from PostgreSQL to SQLite for simplified deployment and maintenance.

---

## Why SQLite?

### Problems with PostgreSQL
- âŒ Server dependency (required running PostgreSQL service)
- âŒ Authentication complexity (user/password/host configuration)
- âŒ Lost database (predator3_dev on 'titan' server no longer accessible)
- âŒ Overkill for single-user news collection application

### Benefits of SQLite
- âœ… **File-based** - No server required, database is a single file
- âœ… **Zero configuration** - Built into Python, no driver installation
- âœ… **Portable** - Easy to backup (copy one file)
- âœ… **Fast** - Adequate for read-heavy news collection workload
- âœ… **Simple** - Perfect for local news aggregator application

---

## Migration Summary

### Configuration Changes

#### `/home/jamaj /src/python/pyTweeter/.env`
```bash
# BEFORE: PostgreSQL connection details
DB_HOST=localhost
DB_PORT=5432
DB_USER=predator
DB_PASSWORD=fuckyou
DB_NAME=predator3_dev

# AFTER: SQLite database file
DB_PATH=predator_news.db
```

### Code Changes (8 files)

All database access files were updated with the following pattern:

#### Database Credentials Function
```python
# BEFORE: Return PostgreSQL connection dict
def dbCredentials():
    conn_cred = {
        'user': config('DB_USER'),
        'password': config('DB_PASSWORD'),
        'host': config('DB_HOST'),
        'dbname': config('DB_NAME')
    }
    return conn_cred

# AFTER: Return SQLite database path
def dbCredentials():
    """Return SQLite database path"""
    db_path = config('DB_PATH', default='predator_news.db')
    if not os.path.isabs(db_path):
        script_dir = os.path.dirname(os.path.abspath(__file__))
        db_path = os.path.join(script_dir, db_path)
    return db_path
```

#### Database Connection
```python
# BEFORE: PostgreSQL connection string
def dbOpen():
    conn = dbCredentials()
    eng = create_engine('postgresql+psycopg2://{user}:{password}@{host}/{dbname}'.format(**conn))
    return eng

# AFTER: SQLite connection string
def dbOpen():
    db_path = dbCredentials()
    eng = create_engine(f'sqlite:///{db_path}')
    return eng
```

#### SQLAlchemy Dialect Import
```python
# BEFORE
from sqlalchemy.dialects.postgresql import insert

# AFTER
from sqlalchemy.dialects.sqlite import insert
```

### Additional Import
```python
import os  # Required for path handling
```

---

## Files Modified

| File | Purpose | Status |
|------|---------|--------|
| `.env` | Configuration | âœ… Updated |
| `requirements.txt` | Dependencies | âœ… psycopg2 removed |
| `predator_gm.py` | Database utilities | âœ… Migrated |
| `wxAsyncNewsGather.py` | News collector (EN/PT) | âœ… Migrated |
| `wxAsyncNewsGather1.py` | News collector (ES/IT) | âœ… Migrated |
| `wxAsyncNewsReaderv2.py` | GUI reader v2 | âœ… Migrated |
| `wxAsyncNewsReaderv3.py` | GUI reader v3 | âœ… Migrated |
| `wxAsyncNewsReaderv4.py` | GUI reader v4 | âœ… Migrated (workaround) |
| `wxAsyncNewsReaderv5.py` | GUI reader v5 | âœ… Migrated |
| `wxListGrid.py` | Grid widget | âœ… Migrated |

### Special Case: wxAsyncNewsReaderv4.py

This file required special handling due to text formatting differences (`import desc` causing pattern mismatches). Fixed using:

1. **sed** to replace import statements:
   ```bash
   sed -i 's/from sqlalchemy.dialects.postgresql import insert/from sqlalchemy.dialects.sqlite import insert/' wxAsyncNewsReaderv4.py
   ```

2. **Python regex script** (`/tmp/fix_v4.py`) to replace functions:
   - Replaced hardcoded API keys with `config()` calls
   - Updated `dbCredentials()` function
   - Updated `dbOpen()` function

---

## Database Schema

The SQLite database (`predator_news.db`) contains the same schema as the PostgreSQL version:

### Tables

#### `gm_sources`
Stores news sources (NewsAPI + RSS feeds)

| Column | Type | Description |
|--------|------|-------------|
| `id_source` | TEXT | Primary key, source identifier |
| `name` | TEXT | Source name |
| `description` | TEXT | Source description |
| `url` | TEXT | Source URL |
| `category` | TEXT | Category (technology_ai, science, business, etc.) |
| `language` | TEXT | Language code (en, pt, es, it) |
| `country` | TEXT | Country code |

#### `gm_articles`
Stores collected news articles

| Column | Type | Description |
|--------|------|-------------|
| `id_article` | TEXT | Primary key, article hash |
| `id_source` | TEXT | Foreign key to gm_sources |
| `author` | TEXT | Article author |
| `title` | TEXT | Article title |
| `description` | TEXT | Article description/summary |
| `url` | TEXT | Article URL (UNIQUE) |
| `urlToImage` | TEXT | Article image URL |
| `publishedAt` | TEXT | Publication timestamp |
| `content` | TEXT | Article content |

---

## Database Setup

### Setup Script: `setup_sqlite_database.py`

Automated script to:
1. Create SQLite database file (`predator_news.db`)
2. Create tables (`gm_sources`, `gm_articles`)
3. Populate sources from `newsapi_sources_by_category.json` (176 NewsAPI sources)
4. Populate RSS feeds from `rssfeeds_working.conf` (114 RSS feeds)

### Current Database Status

After running `setup_sqlite_database.py`:

```
Database: /home/jamaj/src/python/pyTweeter/predator_news.db
Size: 69632 bytes
Sources: 195 (122 NewsAPI + 73 RSS)
Articles: 0 (will be populated by collectors)
```

### Source Distribution

| Category | Count |
|----------|-------|
| Technology/AI | 28 |
| Science | 13 |
| Business/Economics | 26 |
| Politics/Top News | 109 |
| RSS Feeds | ~73 |

---

## Testing Migration

### 1. Verify Database
```bash
# Check sources count
sqlite3 predator_news.db "SELECT COUNT(*) FROM gm_sources;"

# Check by category
sqlite3 predator_news.db "SELECT category, COUNT(*) FROM gm_sources GROUP BY category;"

# Check tables
sqlite3 predator_news.db ".tables"

# View schema
sqlite3 predator_news.db ".schema gm_sources"
```

### 2. Test News Collection
```bash
# Start news collector (English + Portuguese)
python3 wxAsyncNewsGather.py

# Start news collector (Spanish + Italian)
python3 wxAsyncNewsGather1.py
```

### 3. Test GUI Readers
```bash
# Launch GUI reader (recommended version)
python3 wxAsyncNewsReaderv5.py
```

### 4. Check Articles
```bash
# Count collected articles
sqlite3 predator_news.db "SELECT COUNT(*) FROM gm_articles;"

# View recent articles
sqlite3 predator_news.db "SELECT title, publishedAt FROM gm_articles ORDER BY publishedAt DESC LIMIT 10;"
```

---

## Dependencies

### Removed
- âŒ `psycopg2-binary` (PostgreSQL driver - no longer needed)

### Required
- âœ… `SQLAlchemy` (v2.0.25+) - SQLite support built-in
- âœ… Python 3.11+ (SQLite3 module included)
- âœ… `python-decouple` (for .env configuration)

### Updated requirements.txt
```
# SQLite (built-in with Python - no driver needed)
# psycopg2-binary>=2.9.9  # PostgreSQL - NOT USED ANYMORE
SQLAlchemy>=2.0.25
```

---

## Backup Strategy

### Simple File-Based Backup

```bash
# Backup database (copy file)
cp predator_news.db backups/predator_news_$(date +%Y%m%d).db

# Restore database (replace file)
cp backups/predator_news_20260226.db predator_news.db
```

### Export to SQL
```bash
# Export entire database
sqlite3 predator_news.db .dump > predator_news_backup.sql

# Restore from SQL
sqlite3 predator_news.db < predator_news_backup.sql
```

### Export to JSON
```bash
# Use Python script to export to JSON (custom)
python3 export_database.py
```

---

## Performance Considerations

### When SQLite is Appropriate
- âœ… **Read-heavy workload** - News collection and display (current use case)
- âœ… **Single user** - Local news reader (not multi-user web app)
- âœ… **Moderate data** - Thousands to millions of articles (SQLite handles up to ~140 TB)
- âœ… **Simple queries** - SELECT, INSERT operations (no complex joins/aggregations)

### When to Consider PostgreSQL
- âš ï¸ Multiple concurrent writers (SQLite locks entire database on write)
- âš ï¸ Web application with many users
- âš ï¸ Complex analytical queries requiring advanced features
- âš ï¸ High-frequency writes from multiple processes

**For this news collection system: SQLite is perfect.**

---

## Troubleshooting

### Database Locked Error
```
sqlite3.OperationalError: database is locked
```

**Solution:** Only one writer at a time. Don't run multiple news collectors simultaneously or use WAL mode:

```python
engine = create_engine(f'sqlite:///{db_path}', 
                      connect_args={'check_same_thread': False,
                                   'timeout': 30})
```

### Database Not Found
```
sqlalchemy.exc.OperationalError: (sqlite3.OperationalError) unable to open database file
```

**Solution:** Check database path in `.env` and that script has write permissions to the directory.

### Import Error
```
ModuleNotFoundError: No module named 'psycopg2'
```

**Solution:** Old code still referencing PostgreSQL. Check:
1. All `import psycopg2` removed
2. All `from sqlalchemy.dialects.postgresql` changed to `.sqlite`

---

## Next Steps

### Completed âœ…
- [x] Update configuration (.env) to use SQLite
- [x] Migrate 8+ Python files to SQLite connections
- [x] Remove PostgreSQL dependencies (psycopg2)
- [x] Create database setup script
- [x] Populate sources (NewsAPI + RSS)
- [x] Test database creation and population

### Recommended ðŸŽ¯
- [ ] Test news Collection with SQLite backend
- [ ] Test GUI readers with SQLite data
- [ ] Set up automatic news collection (cron/systemd)
- [ ] Implement database backup script
- [ ] Add database vacuum/cleanup script (remove old articles)
- [ ] Monitor database size and performance
- [ ] Get 2 more unique NewsAPI keys (currently KEY3=KEY1, KEY4=KEY2)

### Optional ðŸ’¡
- [ ] Add database statistics dashboard
- [ ] Implement full-text search (SQLite FTS5)
- [ ] Add article deduplication based on content similarity
- [ ] Create export tools (JSON, CSV, etc.)
- [ ] Add article tagging/categorization ML model

---

## References

- [SQLite Documentation](https://www.sqlite.org/docs.html)
- [SQLAlchemy SQLite Dialect](https://docs.sqlalchemy.org/en/20/dialects/sqlite.html)
- [Python sqlite3 module](https://docs.python.org/3/library/sqlite3.html)
- Original PostgreSQL migration: `CREDENTIALS_MIGRATION.md`

---

**Migration completed successfully on February 26, 2026.**  
**Next: Run news collectors and verify article collection!**
